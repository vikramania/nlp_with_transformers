{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnONkldqH49pDQAgmQleCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikramania/nlp_with_transformers/blob/learning_arc/Chapter1_(also_includes_preface).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ANEpgT4Z-p0",
        "outputId": "b0540a58-8f6c-463f-8179-288626cb93e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Google uses Bert to enhance it's search engine.\n",
        "- Similarly GPT family of models from OpenAI\n",
        "  - What are the list of models from OpenAI in GPT family\n",
        "\n",
        "- You have to use GitHub's Copilot... this application is based on transformers.\n",
        "  - try going throught the source code of it if'its public.\n",
        "  - this app is a type of code generating model. (where nazanin (colleague at Oracle Netsuite is trying to work on)\n",
        "  - she is trying to create a model which generates Suite Script.\n",
        "\n",
        "  - Base ideas of transformers:\n",
        "    1. Attention\n",
        "    2. transfer learning\n",
        "    3. scaling up NN.\n",
        "\n",
        "- what exactly is the research community and how to be part of it?\n",
        "\n",
        "- Transformers library and surrounding ecosystem (what is in ecosystem?)\n",
        "  - it made easy to USE, TRAIN and SHARE models\n",
        "\n",
        "\n",
        "- What is the diff bw DS and ML Engi\n",
        "\n"
      ],
      "metadata": {
        "id": "4U38zJPsbOsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers offers several layers of abstraction for using and training transformer models.\n",
        "\n",
        "- HF Trainer API\n",
        "- HF package:\n",
        "  1. Transformers\n",
        "  2. Accelerate\n",
        "  3. Datasets\n",
        "\n",
        "\n",
        "- If you have a less memory GPU you can reduce the batch size when training the models."
      ],
      "metadata": {
        "id": "e027uL5xfY61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get to know about this people:\n",
        "\n",
        "- fastdoc creators Jeremy Howard Sylain Gugger\n",
        "- Quentin Lhoest - HF Datasets\n",
        "- Lysandre Debut HF Hub\n",
        "- Sylvain Guger - HF Accelerate\n",
        "- Joe Davison - zero-shot learning\n"
      ],
      "metadata": {
        "id": "Z5-cAsQwgubw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nowadays, the GPUs on Colab tend to be K80s (which have limited memory), so we recommend using Kaggle, Gradient, or SageMaker Studio Lab. These platforms tend to provide more performant GPUs like P100s, all for free!\n",
        "\n",
        "Neural Network Architecutre for sequence modeling = Transformer\n",
        "\n",
        "1. encoder-decoder framework\n",
        "2. Attention mechanisms\n",
        "3. Transfer learning"
      ],
      "metadata": {
        "id": "higAOsaLiz-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cXpkpZCOr9ZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "hf_task = ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation',\n",
        "           'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation',\n",
        "           'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis',\n",
        "           'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech',\n",
        "           'text2text-generation', 'token-classification', 'translation', 'video-classification',\n",
        "           'visual-question-answering','vqa', 'zero-shot-audio-classification',\n",
        "           'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\n",
        "\n",
        "classifier = pipeline('text-classification')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGd7OCxVJT2l",
        "outputId": "7ba9fc9a-ff10-44ee-8b89-a780366104c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure\n",
        "from your online store in Germany. Unfortunately, when I opened the package,\n",
        "I discovered to my horror that I had been sent an action figure of Megatron\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\"\n",
        "sa = pipeline('sentiment-analysis')\n",
        "results = classifier(text)\n",
        "results = pd.DataFrame(results)\n",
        "sa_results = pd.DataFrame(sa(text))\n",
        "results,sa_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nRCuz-0JYBh",
        "outputId": "dc15de18-a30b-48e9-cfba-de6fcf411cbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      label     score\n",
              " 0  NEGATIVE  0.901546,\n",
              "       label     score\n",
              " 0  NEGATIVE  0.901546)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "ner_tagger = pipeline('ner',aggregation_strategy='simple')\n",
        "outputs = ner_tagger(text)\n",
        "outputs = pd.DataFrame(outputs)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "xW5t0XO9KVgu",
        "outputId": "db808ea3-8384-477d-d268-eb4376ff99ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  entity_group     score           word  start  end\n",
              "0          ORG  0.879010         Amazon      5   11\n",
              "1         MISC  0.990859  Optimus Prime     36   49\n",
              "2          LOC  0.999755        Germany     90   97\n",
              "3         MISC  0.556571           Mega    208  212\n",
              "4          PER  0.590256         ##tron    212  216\n",
              "5          ORG  0.669692         Decept    253  259\n",
              "6         MISC  0.498349        ##icons    259  264\n",
              "7         MISC  0.775362       Megatron    350  358\n",
              "8         MISC  0.987854  Optimus Prime    367  380\n",
              "9          PER  0.812096      Bumblebee    502  511"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-914fd59e-34a5-46b2-8083-5a06f6f3bd11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity_group</th>\n",
              "      <th>score</th>\n",
              "      <th>word</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ORG</td>\n",
              "      <td>0.879010</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.990859</td>\n",
              "      <td>Optimus Prime</td>\n",
              "      <td>36</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LOC</td>\n",
              "      <td>0.999755</td>\n",
              "      <td>Germany</td>\n",
              "      <td>90</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.556571</td>\n",
              "      <td>Mega</td>\n",
              "      <td>208</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PER</td>\n",
              "      <td>0.590256</td>\n",
              "      <td>##tron</td>\n",
              "      <td>212</td>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ORG</td>\n",
              "      <td>0.669692</td>\n",
              "      <td>Decept</td>\n",
              "      <td>253</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.498349</td>\n",
              "      <td>##icons</td>\n",
              "      <td>259</td>\n",
              "      <td>264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.775362</td>\n",
              "      <td>Megatron</td>\n",
              "      <td>350</td>\n",
              "      <td>358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.987854</td>\n",
              "      <td>Optimus Prime</td>\n",
              "      <td>367</td>\n",
              "      <td>380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PER</td>\n",
              "      <td>0.812096</td>\n",
              "      <td>Bumblebee</td>\n",
              "      <td>502</td>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-914fd59e-34a5-46b2-8083-5a06f6f3bd11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-914fd59e-34a5-46b2-8083-5a06f6f3bd11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-914fd59e-34a5-46b2-8083-5a06f6f3bd11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c43f344-289d-4834-8a21-3102a54c37a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c43f344-289d-4834-8a21-3102a54c37a7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c43f344-289d-4834-8a21-3102a54c37a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(ner_tagger(text),indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esyj7FuXLZ5a",
        "outputId": "a393d6f6-039c-4d30-dc2a-1a55c65ffe03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   {   'end': 11,\n",
            "        'entity_group': 'ORG',\n",
            "        'score': 0.8790103,\n",
            "        'start': 5,\n",
            "        'word': 'Amazon'},\n",
            "    {   'end': 49,\n",
            "        'entity_group': 'MISC',\n",
            "        'score': 0.9908588,\n",
            "        'start': 36,\n",
            "        'word': 'Optimus Prime'},\n",
            "    {   'end': 97,\n",
            "        'entity_group': 'LOC',\n",
            "        'score': 0.9997547,\n",
            "        'start': 90,\n",
            "        'word': 'Germany'},\n",
            "    {   'end': 212,\n",
            "        'entity_group': 'MISC',\n",
            "        'score': 0.5565707,\n",
            "        'start': 208,\n",
            "        'word': 'Mega'},\n",
            "    {   'end': 216,\n",
            "        'entity_group': 'PER',\n",
            "        'score': 0.59025556,\n",
            "        'start': 212,\n",
            "        'word': '##tron'},\n",
            "    {   'end': 259,\n",
            "        'entity_group': 'ORG',\n",
            "        'score': 0.66969216,\n",
            "        'start': 253,\n",
            "        'word': 'Decept'},\n",
            "    {   'end': 264,\n",
            "        'entity_group': 'MISC',\n",
            "        'score': 0.49834937,\n",
            "        'start': 259,\n",
            "        'word': '##icons'},\n",
            "    {   'end': 358,\n",
            "        'entity_group': 'MISC',\n",
            "        'score': 0.77536213,\n",
            "        'start': 350,\n",
            "        'word': 'Megatron'},\n",
            "    {   'end': 380,\n",
            "        'entity_group': 'MISC',\n",
            "        'score': 0.98785394,\n",
            "        'start': 367,\n",
            "        'word': 'Optimus Prime'},\n",
            "    {   'end': 511,\n",
            "        'entity_group': 'PER',\n",
            "        'score': 0.8120962,\n",
            "        'start': 502,\n",
            "        'word': 'Bumblebee'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extractive Question-Answering\n",
        "reader = pipeline('question-answering')\n",
        "question = \"What is the customer asking for?\"\n",
        "outputs = reader(question=question,context=text)\n",
        "pd.DataFrame([outputs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "BXMoAYnQL-5w",
        "outputId": "15cf4fb2-998e-4f11-aba1-92c580257ae8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      score  start  end                   answer\n",
              "0  0.416111    335  358  an exchange of Megatron"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd948646-db0d-43f2-a16f-03f6904f615a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.416111</td>\n",
              "      <td>335</td>\n",
              "      <td>358</td>\n",
              "      <td>an exchange of Megatron</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd948646-db0d-43f2-a16f-03f6904f615a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd948646-db0d-43f2-a16f-03f6904f615a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd948646-db0d-43f2-a16f-03f6904f615a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.DataFrame(outputs) # it throws error because the outputs is a direct dict but not list of dicts, replicate the error so that you understand better"
      ],
      "metadata": {
        "id": "H3miCNA_MqLu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline('summarization')\n",
        "outputs = summarizer(text,\n",
        "                     min_length=10,\n",
        "                     max_length=20,\n",
        "                     clean_up_tokenization_spaces=True)\n",
        "print(outputs[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCtSJtT7NBpB",
        "outputId": "6a32e420-15e4-4d27-ec25-fe5b488c3384"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "\n",
        "translator = pipeline('translation_en_to_de', model='Helsinki-NLP/opus-mt-en-de')\n",
        "# hindi_translator = pipeline('translation_en_to_de', model='SoyGema/english-hindi')\n",
        "outputs = translator(text,\n",
        "                     clean_up_tokenization_spaces=True,\n",
        "                     min_length=100)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvH7Z6K4N8cS",
        "outputId": "a6f1d3d4-c23a-4ed8-f2a8-1107027001c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "[{'translation_text': '                                                                                                                                                     '}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline('text-generation')\n",
        "response = \"Dear Bumblebee, I'm sorry to hear that your order got mixed up\"\n",
        "prompt = text + \"\\n\\nCustomer service response:\\n\"\n",
        "outputs = generator(prompt, max_length=200)\n",
        "print(outputs[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z23VpUwQOpSX",
        "outputId": "4033f02a-9a63-4924-c148-0b1333c2d258"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Amazon, last week I ordered an Optimus Prime action figure\n",
            "from your online store in Germany. Unfortunately, when I opened the package,\n",
            "I discovered to my horror that I had been sent an action figure of Megatron\n",
            "instead! As a lifelong enemy of the Decepticons, I hope you can understand my\n",
            "dilemma. To resolve the issue, I demand an exchange of Megatron for the\n",
            "Optimus Prime figure I ordered. Enclosed are copies of my records concerning\n",
            "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\n",
            "\n",
            "Customer service response:\n",
            "\n",
            "Dear Bumblebee:\n",
            "\n",
            "Dear Bumblebee:\n",
            "\n",
            "Yes, I just received your mail and thought it was worth $100,000. I am pleased to find that my order has been exchanged\n",
            "\n",
            "for Optimus Prime. Once again, thank you and thank you so much for your generosity.\n",
            "\n",
            "Thank you and thank you more.\n",
            "\n",
            "We\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcnP7957Qv5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}